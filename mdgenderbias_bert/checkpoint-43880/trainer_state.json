{
  "best_metric": 0.2897173762321472,
  "best_model_checkpoint": "mdgenderbias_bert\\checkpoint-21940",
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 43880,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02,
      "grad_norm": 7.899115562438965,
      "learning_rate": 1.977210574293528e-05,
      "loss": 0.632,
      "step": 500
    },
    {
      "epoch": 0.05,
      "grad_norm": 8.819112777709961,
      "learning_rate": 1.9544211485870555e-05,
      "loss": 0.4554,
      "step": 1000
    },
    {
      "epoch": 0.07,
      "grad_norm": 13.60871410369873,
      "learning_rate": 1.9316317228805835e-05,
      "loss": 0.4301,
      "step": 1500
    },
    {
      "epoch": 0.09,
      "grad_norm": 6.058439254760742,
      "learning_rate": 1.9088422971741115e-05,
      "loss": 0.4172,
      "step": 2000
    },
    {
      "epoch": 0.11,
      "grad_norm": 13.576598167419434,
      "learning_rate": 1.8860528714676392e-05,
      "loss": 0.3983,
      "step": 2500
    },
    {
      "epoch": 0.14,
      "grad_norm": 12.149919509887695,
      "learning_rate": 1.863263445761167e-05,
      "loss": 0.3865,
      "step": 3000
    },
    {
      "epoch": 0.16,
      "grad_norm": 10.941991806030273,
      "learning_rate": 1.8404740200546946e-05,
      "loss": 0.3726,
      "step": 3500
    },
    {
      "epoch": 0.18,
      "grad_norm": 9.097623825073242,
      "learning_rate": 1.8176845943482226e-05,
      "loss": 0.3718,
      "step": 4000
    },
    {
      "epoch": 0.21,
      "grad_norm": 11.869604110717773,
      "learning_rate": 1.7948951686417502e-05,
      "loss": 0.387,
      "step": 4500
    },
    {
      "epoch": 0.23,
      "grad_norm": 12.18720531463623,
      "learning_rate": 1.7721057429352783e-05,
      "loss": 0.3621,
      "step": 5000
    },
    {
      "epoch": 0.25,
      "grad_norm": 3.3931872844696045,
      "learning_rate": 1.749316317228806e-05,
      "loss": 0.3571,
      "step": 5500
    },
    {
      "epoch": 0.27,
      "grad_norm": 3.5927886962890625,
      "learning_rate": 1.726526891522334e-05,
      "loss": 0.361,
      "step": 6000
    },
    {
      "epoch": 0.3,
      "grad_norm": 14.576594352722168,
      "learning_rate": 1.7037374658158616e-05,
      "loss": 0.3586,
      "step": 6500
    },
    {
      "epoch": 0.32,
      "grad_norm": 10.297513961791992,
      "learning_rate": 1.6809480401093893e-05,
      "loss": 0.3499,
      "step": 7000
    },
    {
      "epoch": 0.34,
      "grad_norm": 8.049631118774414,
      "learning_rate": 1.6581586144029173e-05,
      "loss": 0.3529,
      "step": 7500
    },
    {
      "epoch": 0.36,
      "grad_norm": 13.691970825195312,
      "learning_rate": 1.635369188696445e-05,
      "loss": 0.3282,
      "step": 8000
    },
    {
      "epoch": 0.39,
      "grad_norm": 11.67617130279541,
      "learning_rate": 1.612579762989973e-05,
      "loss": 0.3451,
      "step": 8500
    },
    {
      "epoch": 0.41,
      "grad_norm": 4.721872329711914,
      "learning_rate": 1.5897903372835007e-05,
      "loss": 0.324,
      "step": 9000
    },
    {
      "epoch": 0.43,
      "grad_norm": 13.715059280395508,
      "learning_rate": 1.5670009115770283e-05,
      "loss": 0.3423,
      "step": 9500
    },
    {
      "epoch": 0.46,
      "grad_norm": 11.315714836120605,
      "learning_rate": 1.544211485870556e-05,
      "loss": 0.3327,
      "step": 10000
    },
    {
      "epoch": 0.48,
      "grad_norm": 6.5384979248046875,
      "learning_rate": 1.5214220601640838e-05,
      "loss": 0.3285,
      "step": 10500
    },
    {
      "epoch": 0.5,
      "grad_norm": 11.960065841674805,
      "learning_rate": 1.4986326344576119e-05,
      "loss": 0.3257,
      "step": 11000
    },
    {
      "epoch": 0.52,
      "grad_norm": 9.680868148803711,
      "learning_rate": 1.4758432087511397e-05,
      "loss": 0.3194,
      "step": 11500
    },
    {
      "epoch": 0.55,
      "grad_norm": 16.159332275390625,
      "learning_rate": 1.4530537830446674e-05,
      "loss": 0.3209,
      "step": 12000
    },
    {
      "epoch": 0.57,
      "grad_norm": 13.798442840576172,
      "learning_rate": 1.430264357338195e-05,
      "loss": 0.3108,
      "step": 12500
    },
    {
      "epoch": 0.59,
      "grad_norm": 16.143577575683594,
      "learning_rate": 1.4074749316317229e-05,
      "loss": 0.318,
      "step": 13000
    },
    {
      "epoch": 0.62,
      "grad_norm": 7.701740741729736,
      "learning_rate": 1.3846855059252509e-05,
      "loss": 0.3252,
      "step": 13500
    },
    {
      "epoch": 0.64,
      "grad_norm": 14.839254379272461,
      "learning_rate": 1.3618960802187786e-05,
      "loss": 0.3231,
      "step": 14000
    },
    {
      "epoch": 0.66,
      "grad_norm": 15.025217056274414,
      "learning_rate": 1.3391066545123064e-05,
      "loss": 0.3176,
      "step": 14500
    },
    {
      "epoch": 0.68,
      "grad_norm": 3.0132250785827637,
      "learning_rate": 1.3163172288058341e-05,
      "loss": 0.306,
      "step": 15000
    },
    {
      "epoch": 0.71,
      "grad_norm": 13.627669334411621,
      "learning_rate": 1.2935278030993621e-05,
      "loss": 0.3148,
      "step": 15500
    },
    {
      "epoch": 0.73,
      "grad_norm": 6.246889591217041,
      "learning_rate": 1.2707383773928898e-05,
      "loss": 0.3117,
      "step": 16000
    },
    {
      "epoch": 0.75,
      "grad_norm": 15.739224433898926,
      "learning_rate": 1.2479489516864176e-05,
      "loss": 0.3151,
      "step": 16500
    },
    {
      "epoch": 0.77,
      "grad_norm": 8.009055137634277,
      "learning_rate": 1.2251595259799453e-05,
      "loss": 0.2997,
      "step": 17000
    },
    {
      "epoch": 0.8,
      "grad_norm": 10.1065034866333,
      "learning_rate": 1.2023701002734731e-05,
      "loss": 0.2967,
      "step": 17500
    },
    {
      "epoch": 0.82,
      "grad_norm": 11.694458961486816,
      "learning_rate": 1.1795806745670012e-05,
      "loss": 0.3012,
      "step": 18000
    },
    {
      "epoch": 0.84,
      "grad_norm": 6.919264316558838,
      "learning_rate": 1.1567912488605288e-05,
      "loss": 0.302,
      "step": 18500
    },
    {
      "epoch": 0.87,
      "grad_norm": 2.117318868637085,
      "learning_rate": 1.1340018231540567e-05,
      "loss": 0.2939,
      "step": 19000
    },
    {
      "epoch": 0.89,
      "grad_norm": 5.039098739624023,
      "learning_rate": 1.1112123974475843e-05,
      "loss": 0.2852,
      "step": 19500
    },
    {
      "epoch": 0.91,
      "grad_norm": 11.87049674987793,
      "learning_rate": 1.0884229717411122e-05,
      "loss": 0.2962,
      "step": 20000
    },
    {
      "epoch": 0.93,
      "grad_norm": 6.6516947746276855,
      "learning_rate": 1.06563354603464e-05,
      "loss": 0.2929,
      "step": 20500
    },
    {
      "epoch": 0.96,
      "grad_norm": 10.399170875549316,
      "learning_rate": 1.0428441203281679e-05,
      "loss": 0.2869,
      "step": 21000
    },
    {
      "epoch": 0.98,
      "grad_norm": 4.610116481781006,
      "learning_rate": 1.0200546946216955e-05,
      "loss": 0.2821,
      "step": 21500
    },
    {
      "epoch": 1.0,
      "eval_accuracy": 0.8871059705139692,
      "eval_loss": 0.2897173762321472,
      "eval_runtime": 1949.0426,
      "eval_samples_per_second": 25.196,
      "eval_steps_per_second": 1.575,
      "step": 21940
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.632042646408081,
      "learning_rate": 9.972652689152234e-06,
      "loss": 0.2735,
      "step": 22000
    },
    {
      "epoch": 1.03,
      "grad_norm": 1.4639359712600708,
      "learning_rate": 9.744758432087512e-06,
      "loss": 0.1821,
      "step": 22500
    },
    {
      "epoch": 1.05,
      "grad_norm": 12.217546463012695,
      "learning_rate": 9.516864175022789e-06,
      "loss": 0.1776,
      "step": 23000
    },
    {
      "epoch": 1.07,
      "grad_norm": 1.9365828037261963,
      "learning_rate": 9.28896991795807e-06,
      "loss": 0.1752,
      "step": 23500
    },
    {
      "epoch": 1.09,
      "grad_norm": 15.34396743774414,
      "learning_rate": 9.061075660893346e-06,
      "loss": 0.1847,
      "step": 24000
    },
    {
      "epoch": 1.12,
      "grad_norm": 21.96861457824707,
      "learning_rate": 8.833181403828624e-06,
      "loss": 0.1921,
      "step": 24500
    },
    {
      "epoch": 1.14,
      "grad_norm": 14.597578048706055,
      "learning_rate": 8.605287146763903e-06,
      "loss": 0.1804,
      "step": 25000
    },
    {
      "epoch": 1.16,
      "grad_norm": 14.325240135192871,
      "learning_rate": 8.377392889699181e-06,
      "loss": 0.1777,
      "step": 25500
    },
    {
      "epoch": 1.19,
      "grad_norm": 10.89764404296875,
      "learning_rate": 8.149498632634458e-06,
      "loss": 0.19,
      "step": 26000
    },
    {
      "epoch": 1.21,
      "grad_norm": 0.05502019450068474,
      "learning_rate": 7.921604375569736e-06,
      "loss": 0.1639,
      "step": 26500
    },
    {
      "epoch": 1.23,
      "grad_norm": 3.563906192779541,
      "learning_rate": 7.693710118505015e-06,
      "loss": 0.1895,
      "step": 27000
    },
    {
      "epoch": 1.25,
      "grad_norm": 13.308648109436035,
      "learning_rate": 7.465815861440292e-06,
      "loss": 0.1894,
      "step": 27500
    },
    {
      "epoch": 1.28,
      "grad_norm": 16.942378997802734,
      "learning_rate": 7.237921604375571e-06,
      "loss": 0.1725,
      "step": 28000
    },
    {
      "epoch": 1.3,
      "grad_norm": 27.28179931640625,
      "learning_rate": 7.010027347310848e-06,
      "loss": 0.1905,
      "step": 28500
    },
    {
      "epoch": 1.32,
      "grad_norm": 35.503807067871094,
      "learning_rate": 6.782133090246127e-06,
      "loss": 0.1836,
      "step": 29000
    },
    {
      "epoch": 1.34,
      "grad_norm": 7.891546249389648,
      "learning_rate": 6.554238833181404e-06,
      "loss": 0.1779,
      "step": 29500
    },
    {
      "epoch": 1.37,
      "grad_norm": 13.81067180633545,
      "learning_rate": 6.326344576116682e-06,
      "loss": 0.1797,
      "step": 30000
    },
    {
      "epoch": 1.39,
      "grad_norm": 39.09189987182617,
      "learning_rate": 6.09845031905196e-06,
      "loss": 0.1794,
      "step": 30500
    },
    {
      "epoch": 1.41,
      "grad_norm": 25.461376190185547,
      "learning_rate": 5.870556061987238e-06,
      "loss": 0.1862,
      "step": 31000
    },
    {
      "epoch": 1.44,
      "grad_norm": 13.548848152160645,
      "learning_rate": 5.6426618049225164e-06,
      "loss": 0.1801,
      "step": 31500
    },
    {
      "epoch": 1.46,
      "grad_norm": 41.152015686035156,
      "learning_rate": 5.414767547857794e-06,
      "loss": 0.1759,
      "step": 32000
    },
    {
      "epoch": 1.48,
      "grad_norm": 27.286209106445312,
      "learning_rate": 5.186873290793072e-06,
      "loss": 0.1811,
      "step": 32500
    },
    {
      "epoch": 1.5,
      "grad_norm": 28.86810874938965,
      "learning_rate": 4.958979033728351e-06,
      "loss": 0.1678,
      "step": 33000
    },
    {
      "epoch": 1.53,
      "grad_norm": 30.21375846862793,
      "learning_rate": 4.7310847766636284e-06,
      "loss": 0.1705,
      "step": 33500
    },
    {
      "epoch": 1.55,
      "grad_norm": 17.97902488708496,
      "learning_rate": 4.503190519598907e-06,
      "loss": 0.1637,
      "step": 34000
    },
    {
      "epoch": 1.57,
      "grad_norm": 11.723309516906738,
      "learning_rate": 4.2752962625341845e-06,
      "loss": 0.1712,
      "step": 34500
    },
    {
      "epoch": 1.6,
      "grad_norm": 8.765729904174805,
      "learning_rate": 4.047402005469462e-06,
      "loss": 0.1601,
      "step": 35000
    },
    {
      "epoch": 1.62,
      "grad_norm": 0.08423256874084473,
      "learning_rate": 3.8195077484047405e-06,
      "loss": 0.1771,
      "step": 35500
    },
    {
      "epoch": 1.64,
      "grad_norm": 31.280996322631836,
      "learning_rate": 3.5916134913400185e-06,
      "loss": 0.1625,
      "step": 36000
    },
    {
      "epoch": 1.66,
      "grad_norm": 12.730192184448242,
      "learning_rate": 3.3637192342752965e-06,
      "loss": 0.1785,
      "step": 36500
    },
    {
      "epoch": 1.69,
      "grad_norm": 2.7593235969543457,
      "learning_rate": 3.135824977210575e-06,
      "loss": 0.1728,
      "step": 37000
    },
    {
      "epoch": 1.71,
      "grad_norm": 4.071615695953369,
      "learning_rate": 2.9079307201458525e-06,
      "loss": 0.174,
      "step": 37500
    },
    {
      "epoch": 1.73,
      "grad_norm": 8.750226020812988,
      "learning_rate": 2.6800364630811305e-06,
      "loss": 0.1624,
      "step": 38000
    },
    {
      "epoch": 1.75,
      "grad_norm": 2.7544171810150146,
      "learning_rate": 2.4521422060164085e-06,
      "loss": 0.1697,
      "step": 38500
    },
    {
      "epoch": 1.78,
      "grad_norm": 12.739141464233398,
      "learning_rate": 2.2242479489516865e-06,
      "loss": 0.1557,
      "step": 39000
    },
    {
      "epoch": 1.8,
      "grad_norm": 11.654959678649902,
      "learning_rate": 1.9963536918869645e-06,
      "loss": 0.1771,
      "step": 39500
    },
    {
      "epoch": 1.82,
      "grad_norm": 2.2126145362854004,
      "learning_rate": 1.7684594348222425e-06,
      "loss": 0.1688,
      "step": 40000
    },
    {
      "epoch": 1.85,
      "grad_norm": 5.491201877593994,
      "learning_rate": 1.5405651777575205e-06,
      "loss": 0.1662,
      "step": 40500
    },
    {
      "epoch": 1.87,
      "grad_norm": 8.001460075378418,
      "learning_rate": 1.3126709206927987e-06,
      "loss": 0.1521,
      "step": 41000
    },
    {
      "epoch": 1.89,
      "grad_norm": 35.9430046081543,
      "learning_rate": 1.0847766636280768e-06,
      "loss": 0.1498,
      "step": 41500
    },
    {
      "epoch": 1.91,
      "grad_norm": 11.076151847839355,
      "learning_rate": 8.568824065633547e-07,
      "loss": 0.1437,
      "step": 42000
    },
    {
      "epoch": 1.94,
      "grad_norm": 35.19893264770508,
      "learning_rate": 6.289881494986328e-07,
      "loss": 0.1642,
      "step": 42500
    },
    {
      "epoch": 1.96,
      "grad_norm": 4.3579325675964355,
      "learning_rate": 4.010938924339107e-07,
      "loss": 0.1646,
      "step": 43000
    },
    {
      "epoch": 1.98,
      "grad_norm": 9.6923246383667,
      "learning_rate": 1.7319963536918872e-07,
      "loss": 0.1688,
      "step": 43500
    },
    {
      "epoch": 2.0,
      "eval_accuracy": 0.8996701148489045,
      "eval_loss": 0.3602883219718933,
      "eval_runtime": 2065.1091,
      "eval_samples_per_second": 23.78,
      "eval_steps_per_second": 1.487,
      "step": 43880
    }
  ],
  "logging_steps": 500,
  "max_steps": 43880,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "total_flos": 1.284673873366296e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
