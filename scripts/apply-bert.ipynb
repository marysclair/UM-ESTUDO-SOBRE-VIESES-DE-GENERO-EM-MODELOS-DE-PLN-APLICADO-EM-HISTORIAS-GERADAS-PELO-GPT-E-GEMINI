{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação do modelo e do tokenizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\mclar\\appdata\\roaming\\python\\python312\\site-packages (4.39.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\mclar\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (3.13.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\mclar\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.22.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mclar\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mclar\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mclar\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mclar\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in c:\\users\\mclar\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\mclar\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\mclar\\appdata\\roaming\\python\\python312\\site-packages (from transformers) (0.4.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\python312\\lib\\site-packages (from transformers) (4.66.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\mclar\\appdata\\roaming\\python\\python312\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\python312\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.11.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\mclar\\appdata\\roaming\\python\\python312\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\mclar\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mclar\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\python312\\lib\\site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mclar\\appdata\\roaming\\python\\python312\\site-packages (from requests->transformers) (2024.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig\n",
    "\n",
    "config = BertConfig.from_pretrained(\"mdgenderbias_bert/checkpoint-43880/config.json\")\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"mdgenderbias_bert/checkpoint-43880/model.safetensors\", \n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importação e preparação dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "data_gpt = pd.read_excel(\"data/gpt-3.xlsx\")\n",
    "data_gemini = pd.read_excel(\"data/gemini.xlsx\")\n",
    "\n",
    "data_gpt = data_gpt.drop(['Unnamed: 0'], axis=1)\n",
    "data_gemini = data_gemini.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "def fazer_previsao(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    outputs = model(**inputs)\n",
    "    previsao = torch.argmax(outputs.logits).item()\n",
    "    return previsao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\python312\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\python312\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\python312\\lib\\site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\mclar\\appdata\\roaming\\python\\python312\\site-packages (from nltk) (2023.12.25)\n",
      "Requirement already satisfied: tqdm in c:\\python312\\lib\\site-packages (from nltk) (4.66.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\mclar\\appdata\\roaming\\python\\python312\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def dividir_em_frases(texto):\n",
    "    frases = nltk.sent_tokenize(texto)\n",
    "    return frases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_label(array):\n",
    "    cont_label_0 = 0\n",
    "    cont_label_1 = 0\n",
    "    cont_label_2 = 0\n",
    "    percentage = { \"label_0\": 0, \"label_1\": 0, \"label_2\": 0 }\n",
    "    label = -1\n",
    "    for pred in array:\n",
    "        if pred == 0:\n",
    "            cont_label_0 += 1\n",
    "        elif pred == 1:\n",
    "            cont_label_1 += 1\n",
    "        else:\n",
    "            cont_label_2 += 1\n",
    "\n",
    "    if cont_label_0 > cont_label_1 and cont_label_0 > cont_label_2:\n",
    "        label = 0\n",
    "    elif cont_label_1 > cont_label_0 and cont_label_1 > cont_label_2:\n",
    "        label = 1\n",
    "    else:\n",
    "        label = 2\n",
    "    \n",
    "    percentage[\"label_0\"] = (cont_label_0/len(array))*100\n",
    "    percentage[\"label_1\"] = (cont_label_1/len(array))*100\n",
    "    percentage[\"label_2\"] = (cont_label_2/len(array))*100\n",
    "\n",
    "    return percentage, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gpt = {\n",
    "    \"front-end\": [],\n",
    "    \"back-end\": [],\n",
    "    \"full stack\": [],\n",
    "    \"software testing analyst\": [],\n",
    "    \"network architecture\": [],\n",
    "    \"hardware engineering\": [],\n",
    "    \"SEO\": [],\n",
    "    \"cybersecurity\": [],\n",
    "    \"game\": [],\n",
    "    \"mobile\": [],\n",
    "    \"industrial technology\": [],\n",
    "    \"technology field\": []\n",
    "}\n",
    "\n",
    "for coluna in data_gpt.columns:\n",
    "    prediction_group = []\n",
    "    for texto in data_gpt[coluna]:\n",
    "        prediction = []\n",
    "        frases_divididas = dividir_em_frases(texto)\n",
    "        for frase in frases_divididas:\n",
    "            prediction.append(fazer_previsao(frase))\n",
    "        label_pred = calculate_label(prediction)\n",
    "        prediction_group.append(label_pred)\n",
    "    predictions_gpt[coluna].extend(prediction_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_gemini = {\n",
    "    \"front-end\": [],\n",
    "    \"back-end\": [],\n",
    "    \"full stack\": [],\n",
    "    \"software testing analyst\": [],\n",
    "    \"network architecture\": [],\n",
    "    \"hardware engineering\": [],\n",
    "    \"SEO\": [],\n",
    "    \"cybersecurity\": [],\n",
    "    \"game\": [],\n",
    "    \"mobile\": [],\n",
    "    \"industrial technology\": [],\n",
    "    \"technology field\": []\n",
    "}\n",
    "\n",
    "for coluna in data_gemini.columns:\n",
    "    prediction_group = []\n",
    "    for texto in data_gemini[coluna]:\n",
    "        prediction = []\n",
    "        frases_divididas = dividir_em_frases(texto)\n",
    "        for frase in frases_divididas:\n",
    "            prediction.append(fazer_previsao(frase))\n",
    "        label_pred = calculate_label(prediction)\n",
    "        prediction_group.append(label_pred)\n",
    "    predictions_gemini[coluna].extend(prediction_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predictions_gpt)\n",
    "datatoexcel = pd.ExcelWriter('BERT_gpt_prediction.xlsx')\n",
    "df.to_excel(datatoexcel)\n",
    "datatoexcel.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(predictions_gemini)\n",
    "datatoexcel = pd.ExcelWriter('BERT_gemini_prediction.xlsx')\n",
    "df.to_excel(datatoexcel)\n",
    "datatoexcel.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
